---
layout: default
title: Vu (Cong Duy) Hoang 's Homepage
picture: vu
---
<div class="page-header">
  <div class="row">
    <div class="col-sm-12">
      <h3>Vu (Cong Duy) Hoang</h3>
    </div>
  </div>
  <div class="row">
    <div class="col-sm-6">
      <address>
        PhD Candidate<br/>
        <a href="http://www.cis.unimelb.edu.au">School of Computing and Information Systems</a><br/>
        <a href="http://www.eng.unimelb.edu.au">Melbourne School of Engineering</a><br/>
        <a href="http://www.unimelb.edu.au">The University of Melbourne, VIC, Australia</a><br/>
      </address>
    </div>
    <div class="col-sm-4">
      <a href="mailto:vhoang2@student.unimelb.edu.au"><span class="glyphicon glyphicon-envelope"></span></a> Email<br/>
      <a href="https://scholar.google.com.au/citations?user=UFN7fXQAAAAJ&hl=en">
        <img src="img/ico/gscholar_icon.png" alt=""/>
      </a> Google Scholar<br/>
      <a href="http://github.com/duyvuleo">
        <img src="img/ico/github_icon.png" alt=""/>
      </a> Github <br/>
      <a href="https://www.linkedin.com/in/cdvhoang/">
        <img src="img/ico/linkedin_icon.png" alt=""/>
      </a> LinkedIn
    </div>
  </div>
</div>

<h4>Intro</h4>
<p style="text-align: justify;">I am currently a third-year PhD candidate under the joint supervision of <a href="http://people.eng.unimelb.edu.au/tcohn/">Assoc. Prof. Trevor Cohn</a> and <a href="http://users.monash.edu.au/~gholamrh/">Dr. Reza Haffari</a>. Prior to coming to Melbourne, I spent approximately 7 years (2008-2015) in Singapore for studying at <a href="http://nus.edu.sg/">National University of Singapore (NUS)</a> and then working as a senior research enginneer at <a href="http://www.i2r.a-star.edu.sg/hlt/">HLT department</a>, <a href="http://www.i2r.a-star.edu.sg/">Institute for Infocomm Research (I2R)</a>, <a href="https://www.a-star.edu.sg/">A*STAR</a>. Before that, I was a student/teaching &amp; research assistant/lecturer at <a href="https://www.fit.hcmus.edu.vn/vn/Default.aspx?tabid=325">University of Science</a>, <a href="http://en.vnuhcm.edu.vn/">Vietnam National University at Ho Chi Minh City</a>, Vietnam. During this time, I was a research intern at <a href="http://www.nii.ac.jp/en/">National Institute of Informatics</a> in Tokyo, Japan, working under <a href="https://sites.google.com/site/nhcollier/">Dr. Nigel Collier</a> in a bio-text mining project (BioCaster).</p>
<p style="text-align: justify;">My primary research interests lie on Natural Language Processing and Applied Machine Learning. My current focus is on Deep Learning models (e.g., sequence to sequence learning/inference) applied to structured prediction problems such as: Statistical Machine Translation, Abstractive Summarisation, Parsing.</p>

<h4>Recent Highlights</h4>
<p style="text-align: justify;">*** I've joined Speak.AI (a new startup company headquartered in WA, USA) as an AI scientist, working on developing solutions for on-device conversational AI. </p>
<p style="text-align: justify;">*** I was a research intern at <a href="http://www.europe.naverlabs.com">NAVER LABS Europe</a> (formerly as Xerox Research Centre Europe) from Mar 2018 to June 2018, working with Marc Dymetman on the project "Globally-driven Training Techniques for Neural Machine Translation". </p>
<p style="text-align: justify;">*** <a href="https://github.com/duyvuleo/Transformer-DyNet">Transformer-DyNet</a> is my latest *humble* neural sequence-to-sequence toolkit (written in C++ with <a href="https://github.com/clab/dynet">dynet</a> backend). It implements Google's state-of-the-art Transformer architecture in a simplified manner. It's fast and efficient, can produce very high performance, consistently with <a href="https://github.com/tensorflow/tensor2tensor">Google's tensor2tensor</a> or <a href="https://github.com/awslabs/sockeye">Amazon's Sockeye</a>. This is the first C++ implementation of Transformer in DyNet (I suppose, correct me if I am wrong!). </p>
<p style="text-align: justify;">*** I received the Google Australia PhD Travel Scholarship for my trip to EMNLP 2017. Special thanks to Google Australia.</p>
<p style="text-align: justify;">*** I participated in the 2017 Jelinek Summer Workshop on Speech and Language Technology (JSALT) at CMU, June-August 2017, Pittsburgh, PA, USA. My main research focus will be on <a href="https://duyvuleo.github.io/ws17mt/">Neural Machine Translation conditioned on low/zero resources</a>.</p>

{% for post in site.papers %}
  {% if post.selected %}
    {% include paper.html paper=post %}
  {% endif %}
{% endfor %}


